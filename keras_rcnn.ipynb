{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import pprint\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import config, data_generators\n",
    "from keras_frcnn import losses as losses_helper\n",
    "from keras_frcnn import resnet as nn\n",
    "import keras_frcnn.roi_helpers as roi_helpers\n",
    "from keras.utils import generic_utils\n",
    "\n",
    "sys.setrecursionlimit(40000)\n",
    "\n",
    "\n",
    "def train_net(options):\n",
    "    if not options.train_path:   # if filename is not given\n",
    "        parser.error('Error: path to training data must be specified. Pass --path to command line')\n",
    "\n",
    "    if options.parser == 'pascal_voc':\n",
    "        from keras_frcnn.pascal_voc_parser import get_data\n",
    "    elif options.parser == 'simple':\n",
    "        from keras_frcnn.simple_parser import get_data\n",
    "    else:\n",
    "        raise ValueError(\"Command line option parser must be one of 'pascal_voc' or 'simple'\")\n",
    "\n",
    "    # pass the settings from the command line, and persist them in the config object\n",
    "    C = config.Config()\n",
    "\n",
    "    C.num_rois = int(options.num_rois)\n",
    "    C.use_horizontal_flips = bool(options.horizontal_flips)\n",
    "    C.use_vertical_flips = bool(options.vertical_flips)\n",
    "    C.rot_90 = bool(options.rot_90)\n",
    "\n",
    "    C.model_path = options.output_weight_path\n",
    "\n",
    "    if options.input_weight_path:\n",
    "        C.base_net_weights = options.input_weight_path\n",
    "\n",
    "    all_imgs, classes_count, class_mapping = get_data(options.train_path)\n",
    "\n",
    "    if 'bg' not in classes_count:\n",
    "        classes_count['bg'] = 0\n",
    "        class_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "    C.class_mapping = class_mapping\n",
    "\n",
    "    inv_map = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "    print('Training images per class:')\n",
    "    pprint.pprint(classes_count)\n",
    "    print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
    "\n",
    "    config_output_filename = options.config_filename\n",
    "\n",
    "    with open(config_output_filename, 'wb') as config_f:\n",
    "        pickle.dump(C,config_f)\n",
    "        print('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))\n",
    "\n",
    "    random.shuffle(all_imgs)\n",
    "\n",
    "    num_imgs = len(all_imgs)\n",
    "\n",
    "    train_imgs = [s for s in all_imgs if s['imageset'] == 'trainval']\n",
    "    val_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n",
    "\n",
    "    print('Num train samples {}'.format(len(train_imgs)))\n",
    "    print('Num val samples {}'.format(len(val_imgs)))\n",
    "\n",
    "\n",
    "    data_gen_train = data_generators.get_anchor_gt(train_imgs, classes_count, C, K.image_dim_ordering(), mode='train')\n",
    "    data_gen_val = data_generators.get_anchor_gt(val_imgs, classes_count, C, K.image_dim_ordering(), mode='val')\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_shape_img = (3, None, None)\n",
    "    else:\n",
    "        input_shape_img = (None, None, 3)\n",
    "\n",
    "    img_input = Input(shape=input_shape_img)\n",
    "    roi_input = Input(shape=(C.num_rois, 4))\n",
    "\n",
    "    # define the base network (resnet here, can be VGG, Inception, etc)\n",
    "    shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "    # define the RPN, built on the base layers\n",
    "    num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "    rpn = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "    classifier = nn.classifier(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n",
    "\n",
    "    model_rpn = Model(img_input, rpn[:2])\n",
    "    model_classifier = Model([img_input, roi_input], classifier)\n",
    "\n",
    "    # this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
    "    model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
    "\n",
    "    try:\n",
    "        print('loading weights from {}'.format(C.base_net_weights))\n",
    "        model_rpn.load_weights(C.base_net_weights, by_name=True)\n",
    "        model_classifier.load_weights(C.base_net_weights, by_name=True)\n",
    "    except:\n",
    "        print('Could not load pretrained model weights. Weights can be found at {} and {}'.format(\n",
    "            'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels_notop.h5',\n",
    "            'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "        ))\n",
    "\n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    optimizer_classifier = Adam(lr=1e-4)\n",
    "    model_rpn.compile(optimizer=optimizer, loss=[losses_helper.rpn_loss_cls(num_anchors), losses_helper.rpn_loss_regr(num_anchors)])\n",
    "    model_classifier.compile(optimizer=optimizer_classifier, loss=[losses_helper.class_loss_cls, losses_helper.class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
    "    model_all.compile(optimizer='sgd', loss='mae')\n",
    "\n",
    "    epoch_length = 1000\n",
    "    num_epochs = int(options.num_epochs)\n",
    "    iter_num = 0\n",
    "\n",
    "    losses = np.zeros((epoch_length, 5))\n",
    "    rpn_accuracy_rpn_monitor = []\n",
    "    rpn_accuracy_for_epoch = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_loss = np.Inf\n",
    "\n",
    "    class_mapping_inv = {v: k for k, v in class_mapping.items()}\n",
    "    print('Starting training')\n",
    "\n",
    "\n",
    "    for epoch_num in range(num_epochs):\n",
    "\n",
    "        progbar = generic_utils.Progbar(epoch_length)\n",
    "        print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
    "                    mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
    "                    rpn_accuracy_rpn_monitor = []\n",
    "                    print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
    "                    if mean_overlapping_bboxes == 0:\n",
    "                        print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
    "\n",
    "                X, Y, img_data = next(data_gen_train)\n",
    "\n",
    "                loss_rpn = model_rpn.train_on_batch(X, Y)\n",
    "\n",
    "                P_rpn = model_rpn.predict_on_batch(X)\n",
    "\n",
    "                R = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_dim_ordering(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
    "\n",
    "                # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
    "                X2, Y1, Y2 = roi_helpers.calc_iou(R, img_data, C, class_mapping)\n",
    "\n",
    "                if X2 is None:\n",
    "                    rpn_accuracy_rpn_monitor.append(0)\n",
    "                    rpn_accuracy_for_epoch.append(0)\n",
    "                    continue\n",
    "\n",
    "                neg_samples = np.where(Y1[0, :, -1] == 1)\n",
    "                pos_samples = np.where(Y1[0, :, -1] == 0)\n",
    "\n",
    "                if len(neg_samples) > 0:\n",
    "                    neg_samples = neg_samples[0]\n",
    "                else:\n",
    "                    neg_samples = []\n",
    "\n",
    "                if len(pos_samples) > 0:\n",
    "                    pos_samples = pos_samples[0]\n",
    "                else:\n",
    "                    pos_samples = []\n",
    "\n",
    "                rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
    "                rpn_accuracy_for_epoch.append((len(pos_samples)))\n",
    "\n",
    "                if C.num_rois > 1:\n",
    "                    if len(pos_samples) < C.num_rois//2:\n",
    "                        selected_pos_samples = pos_samples.tolist()\n",
    "                    else:\n",
    "                        selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
    "                    try:\n",
    "                        selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
    "                    except:\n",
    "                        selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
    "\n",
    "                    sel_samples = selected_pos_samples + selected_neg_samples\n",
    "                else:\n",
    "                    # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
    "                    selected_pos_samples = pos_samples.tolist()\n",
    "                    selected_neg_samples = neg_samples.tolist()\n",
    "                    if np.random.randint(0, 2):\n",
    "                        sel_samples = random.choice(neg_samples)\n",
    "                    else:\n",
    "                        sel_samples = random.choice(pos_samples)\n",
    "\n",
    "                loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
    "\n",
    "                losses[iter_num, 0] = loss_rpn[1]\n",
    "                losses[iter_num, 1] = loss_rpn[2]\n",
    "\n",
    "                losses[iter_num, 2] = loss_class[1]\n",
    "                losses[iter_num, 3] = loss_class[2]\n",
    "                losses[iter_num, 4] = loss_class[3]\n",
    "\n",
    "                iter_num += 1\n",
    "\n",
    "                progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
    "                                          ('detector_cls', np.mean(losses[:iter_num, 2])), ('detector_regr', np.mean(losses[:iter_num, 3]))])\n",
    "\n",
    "                if iter_num == epoch_length:\n",
    "                    loss_rpn_cls = np.mean(losses[:, 0])\n",
    "                    loss_rpn_regr = np.mean(losses[:, 1])\n",
    "                    loss_class_cls = np.mean(losses[:, 2])\n",
    "                    loss_class_regr = np.mean(losses[:, 3])\n",
    "                    class_acc = np.mean(losses[:, 4])\n",
    "\n",
    "                    mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
    "                    rpn_accuracy_for_epoch = []\n",
    "\n",
    "                    if C.verbose:\n",
    "                        print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
    "                        print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
    "                        print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
    "                        print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
    "                        print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
    "                        print('Loss Detector regression: {}'.format(loss_class_regr))\n",
    "                        print('Elapsed time: {}'.format(time.time() - start_time))\n",
    "\n",
    "                    curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
    "                    iter_num = 0\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    if curr_loss < best_loss:\n",
    "                        if C.verbose:\n",
    "                            print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
    "                        best_loss = curr_loss\n",
    "                        model_all.save_weights(C.model_path)\n",
    "\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Exception: {}'.format(e))\n",
    "                continue\n",
    "\n",
    "    print('Training complete, exiting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training Args\n",
    "class DictToObject:\n",
    "    '''\n",
    "    helper class to encapsulate all the args from dict to obj\n",
    "    '''\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = {'train_path': 'data/training_data.txt', 'parser': 'simple', 'num_rois': 50,\n",
    "       'horizontal_flips': True, 'vertical_flips': True, 'rot_90': True,\n",
    "       'num_epochs': 2000, 'config_filename': 'config/config.pickle', \n",
    "       'output_weight_path': 'weights/model_frcnn.hdf5', \n",
    "       'input_weight_path': 'weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'}\n",
    "\n",
    "args = DictToObject(**args)\n",
    "\n",
    "train_net(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "from optparse import OptionParser\n",
    "import time\n",
    "from keras_frcnn import config\n",
    "import keras_frcnn.resnet as nn\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras_frcnn import roi_helpers\n",
    "\n",
    "sys.setrecursionlimit(40000)\n",
    "\n",
    "def test_net(options):\n",
    "    if not options.test_path:   # if filename is not given\n",
    "        parser.error('Error: path to test data must be specified. Pass --path to command line')\n",
    "\n",
    "\n",
    "    config_output_filename = options.config_filename\n",
    "\n",
    "    with open(config_output_filename, 'rb') as f_in:\n",
    "        C = pickle.load(f_in)\n",
    "\n",
    "    # turn off any data augmentation at test time\n",
    "    C.use_horizontal_flips = False\n",
    "    C.use_vertical_flips = False\n",
    "    C.rot_90 = False\n",
    "\n",
    "    img_path = options.test_path\n",
    "\n",
    "    def format_img_size(img, C):\n",
    "        \"\"\" formats the image size based on config \"\"\"\n",
    "        img_min_side = float(C.im_size)\n",
    "        (height,width,_) = img.shape\n",
    "\n",
    "        if width <= height:\n",
    "            ratio = img_min_side/width\n",
    "            new_height = int(ratio * height)\n",
    "            new_width = int(img_min_side)\n",
    "        else:\n",
    "            ratio = img_min_side/height\n",
    "            new_width = int(ratio * width)\n",
    "            new_height = int(img_min_side)\n",
    "        img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "        return img, ratio\t\n",
    "\n",
    "    def format_img_channels(img, C):\n",
    "        \"\"\" formats the image channels based on config \"\"\"\n",
    "        img = img[:, :, (2, 1, 0)]\n",
    "        img = img.astype(np.float32)\n",
    "        img[:, :, 0] -= C.img_channel_mean[0]\n",
    "        img[:, :, 1] -= C.img_channel_mean[1]\n",
    "        img[:, :, 2] -= C.img_channel_mean[2]\n",
    "        img /= C.img_scaling_factor\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "\n",
    "    def format_img(img, C):\n",
    "        \"\"\" formats an image for model prediction based on config \"\"\"\n",
    "        img, ratio = format_img_size(img, C)\n",
    "        img = format_img_channels(img, C)\n",
    "        return img, ratio\n",
    "\n",
    "    # Method to transform the coordinates of the bounding box to its original size\n",
    "    def get_real_coordinates(ratio, x1, y1, x2, y2):\n",
    "\n",
    "        real_x1 = int(round(x1 // ratio))\n",
    "        real_y1 = int(round(y1 // ratio))\n",
    "        real_x2 = int(round(x2 // ratio))\n",
    "        real_y2 = int(round(y2 // ratio))\n",
    "\n",
    "        return (real_x1, real_y1, real_x2 ,real_y2)\n",
    "\n",
    "    class_mapping = C.class_mapping\n",
    "\n",
    "    if 'bg' not in class_mapping:\n",
    "        class_mapping['bg'] = len(class_mapping)\n",
    "\n",
    "    class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "    print(class_mapping)\n",
    "    class_to_color = {class_mapping[v]: np.random.randint(0, 255, 3) for v in class_mapping}\n",
    "    C.num_rois = int(options.num_rois)\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_shape_img = (3, None, None)\n",
    "        input_shape_features = (1024, None, None)\n",
    "    else:\n",
    "        input_shape_img = (None, None, 3)\n",
    "        input_shape_features = (None, None, 1024)\n",
    "\n",
    "\n",
    "    img_input = Input(shape=input_shape_img)\n",
    "    roi_input = Input(shape=(C.num_rois, 4))\n",
    "    feature_map_input = Input(shape=input_shape_features)\n",
    "\n",
    "    # define the base network (resnet here, can be VGG, Inception, etc)\n",
    "    shared_layers = nn.nn_base(img_input, trainable=True)\n",
    "\n",
    "    # define the RPN, built on the base layers\n",
    "    num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
    "    rpn_layers = nn.rpn(shared_layers, num_anchors)\n",
    "\n",
    "    classifier = nn.classifier(feature_map_input, roi_input, C.num_rois, nb_classes=len(class_mapping), trainable=True)\n",
    "\n",
    "    model_rpn = Model(img_input, rpn_layers)\n",
    "    model_classifier_only = Model([feature_map_input, roi_input], classifier)\n",
    "\n",
    "    model_classifier = Model([feature_map_input, roi_input], classifier)\n",
    "\n",
    "    model_rpn.load_weights(C.model_path, by_name=True)\n",
    "    model_classifier.load_weights(C.model_path, by_name=True)\n",
    "\n",
    "    model_rpn.compile(optimizer='sgd', loss='mse')\n",
    "    model_classifier.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "    all_imgs = []\n",
    "\n",
    "    classes = {}\n",
    "\n",
    "    bbox_threshold = 0.8\n",
    "\n",
    "    visualise = True\n",
    "    \n",
    "    result_list = [] # Image-Name, n * coordinate_list\n",
    "    for idx, img_name in enumerate(sorted(os.listdir(img_path))):\n",
    "        if not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n",
    "            continue\n",
    "        print(img_name)\n",
    "        row_list = []\n",
    "        row_list.append(img_name)\n",
    "        st = time.time()\n",
    "        filepath = os.path.join(img_path,img_name)\n",
    "\n",
    "        img = cv2.imread(filepath)\n",
    "\n",
    "        X, ratio = format_img(img, C)\n",
    "\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            X = np.transpose(X, (0, 2, 3, 1))\n",
    "\n",
    "        # get the feature maps and output from the RPN\n",
    "        [Y1, Y2, F] = model_rpn.predict(X)\n",
    "\n",
    "\n",
    "        R = roi_helpers.rpn_to_roi(Y1, Y2, C, K.image_dim_ordering(), overlap_thresh=0.7)\n",
    "\n",
    "        # convert from (x1,y1,x2,y2) to (x,y,w,h)\n",
    "        R[:, 2] -= R[:, 0]\n",
    "        R[:, 3] -= R[:, 1]\n",
    "\n",
    "        # apply the spatial pyramid pooling to the proposed regions\n",
    "        bboxes = {}\n",
    "        probs = {}\n",
    "\n",
    "        for jk in range(R.shape[0]//C.num_rois + 1):\n",
    "            ROIs = np.expand_dims(R[C.num_rois*jk:C.num_rois*(jk+1), :], axis=0)\n",
    "            if ROIs.shape[1] == 0:\n",
    "                break\n",
    "\n",
    "            if jk == R.shape[0]//C.num_rois:\n",
    "                #pad R\n",
    "                curr_shape = ROIs.shape\n",
    "                target_shape = (curr_shape[0],C.num_rois,curr_shape[2])\n",
    "                ROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
    "                ROIs_padded[:, :curr_shape[1], :] = ROIs\n",
    "                ROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n",
    "                ROIs = ROIs_padded\n",
    "\n",
    "            [P_cls, P_regr] = model_classifier_only.predict([F, ROIs])\n",
    "\n",
    "            for ii in range(P_cls.shape[1]):\n",
    "\n",
    "                if np.max(P_cls[0, ii, :]) < bbox_threshold or np.argmax(P_cls[0, ii, :]) == (P_cls.shape[2] - 1):\n",
    "                    continue\n",
    "\n",
    "                cls_name = class_mapping[np.argmax(P_cls[0, ii, :])]\n",
    "\n",
    "                if cls_name not in bboxes:\n",
    "                    bboxes[cls_name] = []\n",
    "                    probs[cls_name] = []\n",
    "\n",
    "                (x, y, w, h) = ROIs[0, ii, :]\n",
    "\n",
    "                cls_num = np.argmax(P_cls[0, ii, :])\n",
    "                try:\n",
    "                    (tx, ty, tw, th) = P_regr[0, ii, 4*cls_num:4*(cls_num+1)]\n",
    "                    tx /= C.classifier_regr_std[0]\n",
    "                    ty /= C.classifier_regr_std[1]\n",
    "                    tw /= C.classifier_regr_std[2]\n",
    "                    th /= C.classifier_regr_std[3]\n",
    "                    x, y, w, h = roi_helpers.apply_regr(x, y, w, h, tx, ty, tw, th)\n",
    "                except:\n",
    "                    pass\n",
    "                bboxes[cls_name].append([C.rpn_stride*x, C.rpn_stride*y, C.rpn_stride*(x+w), C.rpn_stride*(y+h)])\n",
    "                probs[cls_name].append(np.max(P_cls[0, ii, :]))\n",
    "\n",
    "        all_dets = []\n",
    "\n",
    "        for key in bboxes:\n",
    "            bbox = np.array(bboxes[key])\n",
    "\n",
    "            new_boxes, new_probs = roi_helpers.non_max_suppression_fast(bbox, np.array(probs[key]), overlap_thresh=0.5)\n",
    "            for jk in range(new_boxes.shape[0]):\n",
    "                (x1, y1, x2, y2) = new_boxes[jk,:]\n",
    "\n",
    "                (real_x1, real_y1, real_x2, real_y2) = get_real_coordinates(ratio, x1, y1, x2, y2)\n",
    "                print(real_x1, real_y1, real_x2, real_y2)\n",
    "                cv2.rectangle(img,(real_x1, real_y1), (real_x2, real_y2), (int(class_to_color[key][0]), int(class_to_color[key][1]), int(class_to_color[key][2])),2)\n",
    "\n",
    "                textLabel = '{}: {}'.format(key,int(100*new_probs[jk]))\n",
    "                all_dets.append((key,100*new_probs[jk]))\n",
    "\n",
    "                (retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,1,1)\n",
    "                textOrg = (real_x1, real_y1-0)\n",
    "\n",
    "                cv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 2)\n",
    "                cv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), -1)\n",
    "                cv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 0), 1)\n",
    "                \n",
    "                coordinate_list = []\n",
    "                coordinate_list.append(real_x1)\n",
    "                coordinate_list.append(real_y1)\n",
    "                coordinate_list.append(real_x2)\n",
    "                coordinate_list.append(real_y2)\n",
    "                coordinate_list.append(key)\n",
    "                coordinate_list.append(100*new_probs[jk])\n",
    "                row_list.append(coordinate_list)\n",
    "        print('Elapsed time = {}'.format(time.time() - st))\n",
    "        print(all_dets)\n",
    "        cv2.imwrite('/home/ubuntu/workspace/keras-frcnn/data/report_detection/result/' + str(img_name) + '.png',img)\n",
    "        \n",
    "        result_list.append(row_list)\n",
    "    #print(result_list)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing Args\n",
    "class DictToObject:\n",
    "    '''\n",
    "    helper class to encapsulate all the args from dict to obj\n",
    "    '''\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = {'test_path': 'data/report_detection/test_data/', 'num_rois': 32,\n",
    "        'config_filename': 'config/config_detection.pickle'\n",
    "       }\n",
    "\n",
    "args = DictToObject(**args)\n",
    "\n",
    "result_list = test_net(args)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### RESULT MATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "API_KEY = 'AIzaSyD-Q6-t7T8xS616M79yF95WO5nWLXeNAz0'\n",
    "import cloudvisreq\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import data_arrays\n",
    "\n",
    "def create_grid(result_list):\n",
    "    '''\n",
    "    iterates over the the result_list for each image,\n",
    "    cuts the image into a grid, sents it to google OCR\n",
    "    and stores the results in a pandas dataframe\n",
    "    '''\n",
    "    df_list = []\n",
    "    \n",
    "    for image in result_list:\n",
    "        column_list = []\n",
    "        row_list = []\n",
    "        header_list = []\n",
    "        table_list = []\n",
    "        for entry in image:\n",
    "            print(entry)\n",
    "            if isinstance(entry, basestring):\n",
    "                image_name = entry\n",
    "            if isinstance(entry, list):\n",
    "                if entry[4] == 'column':\n",
    "                    column_list.append((entry[0], entry[1], entry[2], entry[3]))\n",
    "                elif entry[4] == 'row':\n",
    "                    row_list.append((entry[0], entry[1], entry[2], entry[3]))\n",
    "                elif entry[4] == 'header':\n",
    "                    header_list.append((entry[0], entry[1], entry[2], entry[3]))\n",
    "                    row_list.append((entry[0], entry[1], entry[2], entry[3]))\n",
    "                elif entry[4] == 'table':\n",
    "                    table_list.append((entry[0], entry[1], entry[2], entry[3]))\n",
    "        sorted_columns = sorted(column_list, key=lambda x: x[0])\n",
    "        sorted_rows = sorted(row_list, key=lambda x: x[1])\n",
    "        print(sorted_columns)\n",
    "        print(sorted_rows)\n",
    "        image = cv2.imread('data/test_data/' + image_name)\n",
    "        counter = 1\n",
    "        column_counter = 0\n",
    "        \n",
    "        print(len(sorted_columns))\n",
    "        print(len(sorted_rows))\n",
    "        index = [x for x in range(len(sorted_rows) +1)] # +1 row for the header\n",
    "        columns = [y for y in range(len(sorted_columns))]\n",
    "        \n",
    "        df = pd.DataFrame(index=index, columns=columns)\n",
    "        print(df.shape)\n",
    "        print(df)\n",
    "\n",
    "        for column in sorted_columns:\n",
    "            #print('Column: ' + str(column))\n",
    "            row_counter = 0\n",
    "            for row in sorted_rows:\n",
    "                #print('Row: ' + str(row))\n",
    "                cropped = image[row[1]: row[3], column[0]: column[2]] # startY and endY coordinates, followed\n",
    "                output_file_name = image_name + '_cropped_' + str(counter) + '.png'\n",
    "                output_file_path = os.path.join('data/cropped/', output_file_name)\n",
    "                cv2.imwrite(output_file_path, cropped)\n",
    "                text_result = cloudvisreq.run(API_KEY, str(output_file_path))\n",
    "                #print(text_result)\n",
    "                \n",
    "                output = text_result.split('\\n')\n",
    "                found_entry = ''\n",
    "                for entry in output:\n",
    "                    if entry:\n",
    "                        #print(entry)\n",
    "                        found_entry = found_entry + ' ' + entry\n",
    "                #print(found_entry.strip())\n",
    "                df.set_value(row_counter, column_counter, found_entry.strip()) # df.set_value(index, col, value, takeable=False)\n",
    "                counter += 1\n",
    "                row_counter += 1\n",
    "            column_counter += 1\n",
    "        print(df)\n",
    "        df_list.append(df)\n",
    "        # Writing out the rectangles\n",
    "        for column in sorted_columns:\n",
    "            cv2.rectangle(image, ((column[0] + int(random.uniform(-10, 10))), (column[1] + int(random.uniform(-10, 10)))), ((column[2] + int(random.uniform(-10, 10))), (column[3] + int(random.uniform(-10, 10)))), (255,0,0), 2)\n",
    "        for row in sorted_rows:\n",
    "            cv2.rectangle(image, ((row[0] + int(random.uniform(-30, 30))), (row[1]+ int(random.uniform(-10, 10)))), ((row[2]+ int(random.uniform(-30, 30))), (row[3]+ int(random.uniform(-10, 10)))), (0,255,0), 2)\n",
    "        for header in header_list:\n",
    "            cv2.rectangle(image, (header[0]+ int(random.uniform(-30, 30)), header[1]+ int(random.uniform(-10, 10))), (header[2]+ int(random.uniform(-30, 30)), header[3]+ int(random.uniform(-10, 10))), (0,0,255), 2)\n",
    "        for table in table_list:    \n",
    "            cv2.rectangle(image, (table[0]+ int(random.uniform(-30, 30)), table[1]+ int(random.uniform(-10, 10))), (table[2]+ int(random.uniform(-30, 30)), table[3]+ int(random.uniform(-10, 10))), (0,255,255), 2)\n",
    "        cv2.imwrite('data/result/' + image_name.replace('.jpg', '.png'), image)\n",
    "    return df_list\n",
    "\n",
    "result_list = data_arrays.load_array()\n",
    "for result in result_list:\n",
    "    print(result)\n",
    "df_list = create_grid(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import result_mapping\n",
    "\n",
    "output_dict = {}\n",
    "\n",
    "for df in df_list:\n",
    "    #df.to_csv('parsed_df.csv', encoding='utf-8')\n",
    "    new_df = df.iloc[:,[1,2]]\n",
    "    print(new_df)\n",
    "    for index, row in new_df.iterrows():\n",
    "        if row[1] != 'No text found':\n",
    "            #print('We found a valid value!!!')\n",
    "            #print(row[2].strip())\n",
    "            output_dict['A' + str(row[1])] = str(row[2]).replace(\" \", \"\").replace(\",\", \"\")\n",
    "print(output_dict)\n",
    "\n",
    "result_mapping.df_mapping(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
